{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Copyright 2019 Xilinx Inc.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may \n",
    "not use this file except in compliance with the License. You may obtain\n",
    "a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model for the skin cancer classifier.\n",
    "# Alimul, Xilinx Inc, Dec, 2019\n",
    "# trained with HAM10000 dataset. 7 types of skin lesions. \n",
    "\n",
    "# - Actinic Keratoses\n",
    "# - Basal Cell Carcinoma\n",
    "# - Benign Keratosis\n",
    "# - Dermatofibroma\n",
    "# - Malignant Melanoma\n",
    "# - Melanocytic Nevi\n",
    "# - Vascular Lesions\n",
    "\n",
    "\n",
    "# Import the libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from freeze_session import freeze_session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "# Check if GPU is available\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The paths for the training and validation images\n",
    "train_path = 'data/train_val/train_dir'\n",
    "valid_path = 'data/train_val/val_dir'\n",
    "\n",
    "# Declare a few hyperparameters \n",
    "num_train_samples = 42154\n",
    "num_val_samples = 3002\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "image_size = 224\n",
    "\n",
    "# Steps are needed in an iteration\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generators\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.inception_v3.preprocess_input).flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "valid_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.inception_v3.preprocess_input).flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size)\n",
    "\n",
    "test_batches = ImageDataGenerator(\n",
    "    preprocessing_function= \\\n",
    "        keras.applications.inception_v3.preprocess_input).flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcl =train_batches.classes\n",
    "print(tcl.shape)\n",
    "vcl = valid_batches.classes\n",
    "print(vcl)\n",
    "tscl = test_batches.classes\n",
    "print(tscl)\n",
    "print(test_batches.class_indices.keys())\n",
    "print(valid_batches.class_indices.values())\n",
    "print(test_batches.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a inception_v3 model alonge with weights\n",
    "iv3_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# See a summary of the layers in the model\n",
    "iv3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taking the output of the inception_v3 just before last layer\n",
    "x = iv3_model.output\n",
    "# flattening the outputs of the last conv layer\n",
    "flatten = Flatten()(x)\n",
    "# adding two fully connected layers. Meeting DPU requirement, keeping output/input ratio at @ 1/6\n",
    "dense1 = Dense(2048, activation= 'relu')(flatten)\n",
    "dense3= Dense(128, activation= 'relu')(dense1)\n",
    "# adding the prediction layer with 'softmax'\n",
    "predictions = Dense(7, activation='softmax')(dense3)\n",
    "\n",
    "# Create a new model with the new outputs\n",
    "model = Model(inputs=iv3_model.input, outputs=predictions)\n",
    "\n",
    "# See a summary of the new layers in the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights of the layers that aren't training\n",
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "#for layer in model.layers:\n",
    "    #print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Define Top2 and Top3 Accuracy\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=[categorical_accuracy])\n",
    "\n",
    "# Add weights to make the model more sensitive to melanoma\n",
    "class_weights={\n",
    "    0: 1.0,  # akiec\n",
    "    1: 1.0,  # bcc\n",
    "    2: 1.0,  # bkl\n",
    "    3: 1.0,  # df\n",
    "    4: 3.0,  # mel\n",
    "    5: 1.0,  # nv\n",
    "    6: 1.0,  # vasc\n",
    "}\n",
    "\n",
    "# Declare the filepath for the saved model\n",
    "filepath = \"model/model_incv3_3_12.h5\"\n",
    "\n",
    "# Declare a checkpoint to save the best version of the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "# Reduce the learning rate as the learning stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.2, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.000001)\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch=train_steps,\n",
    "                              class_weight=class_weights,\n",
    "                              validation_data=valid_batches,\n",
    "                              validation_steps=val_steps,\n",
    "                              epochs=30,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrain the trained model\n",
    "\n",
    "# Define Top2 and Top3 Accuracy\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "\n",
    "# Add weights to make the model more sensitive to melanoma\n",
    "class_weights={\n",
    "    0: 1.0,  # akiec\n",
    "    1: 1.0,  # bcc\n",
    "    2: 1.0,  # bkl\n",
    "    3: 1.0,  # df\n",
    "    4: 2.0,  # mel\n",
    "    5: 1.0,  # nv\n",
    "    6: 1.0,  # vasc\n",
    "}\n",
    "\n",
    "# Declare the filepath for the saved model\n",
    "filepath = \"model/model_incv3_2_6.h5\"\n",
    "\n",
    "model=keras.models.load_model(filepath, custom_objects=dependencies)\n",
    "model.summary()\n",
    "\n",
    "# Declare a checkpoint to save the best version of the model\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "# Reduce the learning rate as the learning stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.0000001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit_generator(train_batches,\n",
    "                              steps_per_epoch=train_steps,\n",
    "                              class_weight=class_weights,\n",
    "                              validation_data=valid_batches,\n",
    "                              validation_steps=val_steps,\n",
    "                              epochs=20,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of the best epoch\n",
    "#model.load_weights('model/model_incv3_3_12.h5')\n",
    "model=keras.models.load_model('model/model_incv3_3_13.h5')\n",
    "\n",
    "val_loss, val_cat_acc = \\\n",
    "model.evaluate_generator(test_batches, steps=val_steps)\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_cat_acc:', val_cat_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_batches, steps=val_steps)\n",
    "print(model.metrics_names, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Output node:', [out.op.name for out in model.outputs])\n",
    "print('Input node:',[inp.op.name for inp in model.inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model as .pb file\n",
    "\n",
    "pb_file = \"model/model_incv3_3_13.pb\"\n",
    "frozen_graph = freeze_session(K.get_session(),output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, \".\", pb_file , as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
